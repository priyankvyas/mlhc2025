# -*- coding: utf-8 -*-
"""Data-to-Text_Generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1khMAGN_hlBsSf4NwnZuhx7iS3G4B8_xH
"""

import pandas as pd  # Used for data manipulation and analysis
from datasets import Dataset # Hugging Face Datasets library for working with datasets
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq,Seq2SeqTrainer, Seq2SeqTrainingArguments # components for finetuning the model
import evaluate # for evaluvation metric
from sklearn.model_selection import train_test_split #For splitting data into training and testing sets
import numpy as np # For array manipulations

#path to the pre-trained model
model_path = "/content/drive/MyDrive/IX_Coursework/MLHC/Clinical-T5-Base"
# Load the tokenizer from the specified model path
tokenizer = AutoTokenizer.from_pretrained(model_path)
# Load the pre-trained sequence-to-sequence model from the specified model path
model = AutoModelForSeq2SeqLM.from_pretrained(model_path)

#Defining the control prefix
CONTROL_PREFIX = "data2clinical:"

def create_input_text(row):
    """
    Builds a single string input for data-to-text.  Combines various patient data fields
    into a formatted string for use with a sequence-to-sequence model.
    """

    # Age and sex
    age_val = row.get('AGE', 'Unknown')
    sex_val = row.get('SEX', 'U')

    # Mode of arrival
    arrival_mode = row.get('ARREMS','')

    # Reason for visit(RFV1, RFV2, RFV3)
    rfv1 = row.get('RFV1', '')
    rfv2 = row.get('RFV2', '')
    rfv3 = row.get('RFV3', '')
    reasons = [str(r) for r in [rfv1, rfv2, rfv3] if r]
    reasons_str = '; '.join(reasons) if reasons else 'no reasons'

    # Vital signs
    temp_val   = row.get('TEMPF', 'N/A')
    pulse_val  = row.get('PULSE', 'N/A')
    bpsys_val  = row.get('BPSYS', 'N/A')
    bpdiast_val= row.get('BPDIAS', 'N/A')
    resp_val   = row.get('RESPR', 'N/A')
    o2sat_val  = row.get('POPCT', 'N/A')



    #Total Chronic conditions
    Total_Chronic = row.get('TOTCHRON', 'N/A')
    Alchol_abuse = row.get('ETOHAB', 'N/A')
    Alzheimer = row.get('ALZHD', 'N/A')
    Asthma = row.get('ASTHMA', 'N/A')
    Cancer = row.get('CANCER', 'N/A')
    CVA = row.get('CEBVD', 'N/A')
    CKD = row.get('CKD', 'N/A')
    COPD = row.get('COPD', 'N/A')
    CHF = row.get('CHF', 'N/A')
    CAD = row.get('CAD', 'N/A')
    Depression = row.get('DEPRN', 'N/A')
    DIABTYP1 = row.get('DIABTYP1', 'N/A')
    DIABTYP2 = row.get('DIABTYP2', 'N/A')
    DIABTYP0 = row.get('DIABTYP0', 'N/A')
    ESRD = row.get('ESRD', 'N/A')
    HPE = row.get('HPE', 'N/A')
    EDHIV = row.get('EDHIV', 'N/A')
    HYPLIPID = row.get('HYPLIPID', 'N/A')
    HTN = row.get('HTN', 'N/A')
    OBESITY = row.get('OBESITY', 'N/A')
    OSA = row.get('OSA', 'N/A')
    OSTPRSIS = row.get('OSTPRSIS', 'N/A')
    SUBSTAB = row.get('SUBSTAB', 'N/A')

    #Causes
    cause1 = row.get('CAUSE1', '')
    cause2 = row.get('CAUSE2', '')
    cause3 = row.get('CAUSE3', '')

    causes = [str(r) for r in [cause1, cause2, cause3] if r]
    causes_str = '; '.join(causes) if causes else 'no causes reported'


    #Pain Scale
    pain_scale = row.get('PAINSCALE', 'N/A')

    #Injury indicator
    injury_flag = row.get('INJURY', 0)
    injury_str = 'Yes' if str(injury_flag) == '1' else 'No'

    #Build the input string
    input_str = (
        f"AGE: {age_val} | SEX: {sex_val} | ARRIVAL_AMBULANCE: {arrival_mode} | "
        f"REASONS: {reasons_str} | TEMP: {temp_val} | PULSE: {pulse_val} | "
        f"BP: {bpsys_val}/{bpdiast_val} | RESP: {resp_val} | O2SAT: {o2sat_val} | "
        f"PAIN: {pain_scale} | INJURY: {injury_str} | "
        f"Total Chronic Conditions: {Total_Chronic} | "
        f"Alchol Abuse: {Alchol_abuse} | "
        f"Alzheimer: {Alzheimer} | "
        f"Asthma: {Asthma} | "
        f"Cancer: {Cancer} | "
        f"CVA: {CVA} | "
        f"CKD: {CKD} | "
        f"COPD: {COPD} | "
        f"CHF: {CHF} | "
        f"CAD: {CAD} | "
        f"Depression: {Depression} | "
        f"DIABTYP1: {DIABTYP1} | "
        f"DIABTYP2: {DIABTYP2} | "
        f"DIABTYP0: {DIABTYP0} | "
        f"ESRD: {ESRD} | "
        f"HPE: {HPE} | "
        f"EDHIV: {EDHIV} | "
        f"HYPLIPID: {HYPLIPID} | "
        f"HTN: {HTN} | "
        f"OBESITY: {OBESITY} | "
        f"OSA: {OSA} | "
        f"OSTPRSIS: {OSTPRSIS} | "
        f"SUBSTAB: {SUBSTAB} | "
        f"CAUSES: {causes_str}"


    )

    return CONTROL_PREFIX+input_str

def create_output_text(row):
    """
    Generates a natural-language summary of the ED visit using
    the same variables as in create_input_text(), but in a more
    narrative style.
    """
    def clean_text(txt):
        txt = str(txt).strip()
        return txt if txt.lower() not in ['', 'blank', 'na'] else ''

    # age and sex
    age_val = row.get('AGE', 'Unknown')
    sex_raw = row.get('SEX', 'U')
    if isinstance(sex_raw, str) and sex_raw.strip().upper().startswith('M'):
        sex_str = "male"
    elif isinstance(sex_raw, str) and sex_raw.strip().upper().startswith('F'):
        sex_str = "female"
    else:
        sex_str = "unknown sex"


    # Arrival mode(ARREMS is "yes"/"no" or 1/0)
    arrems_val = str(row.get('ARREMS', '0')).strip().lower()
    if arrems_val in ['1', 'yes', 'y']:
        arrival_mode_str = "arrived by ambulance"
    else:
        arrival_mode_str = "arrived by private vehicle"


    # Reasons for visit
    rfv1 = clean_text(row.get('RFV1', ''))
    rfv2 = clean_text(row.get('RFV2', ''))
    rfv3 = clean_text(row.get('RFV3', ''))

    reasons = [str(r) for r in [rfv1, rfv2, rfv3] if r]
    reasons_str = ", ".join(reasons) if reasons else "no specific complaint"


    # Vital Signs
    temp_val   = row.get('TEMPF', 'N/A')
    pulse_val  = row.get('PULSE', 'N/A')
    bpsys_val  = row.get('BPSYS', 'N/A')
    bpdiast_val= row.get('BPDIAS', 'N/A')
    resp_val   = row.get('RESPR', 'N/A')
    o2sat_val  = row.get('POPCT', 'N/A')

    # Pain scale
    pain_scale = row.get('PAINSCALE', 'N/A')

    # Injury
    injury_flag = row.get('INJURY', 0)
    injury_str = "injury-related" if str(injury_flag) == '1' else "non-injury"


    # Total chronic conditions
    total_chronic = row.get('TOTCHRON', 'N/A')

    # Individual chronic flags (1 = Yes, else 0 or N/A)
    chronic_map = {
        "Alzheimer's/dementia": row.get('ALZHD', '0'),
        "Asthma": row.get('ASTHMA', '0'),
        "Cancer": row.get('CANCER', '0'),
        "Stroke/TIA": row.get('CEBVD', '0'),
        "Chronic kidney disease": row.get('CKD', '0'),
        "COPD": row.get('COPD', '0'),
        "Congestive heart failure": row.get('CHF', '0'),
        "Coronary artery disease": row.get('CAD', '0'),
        "Depression": row.get('DEPRN', '0'),
        "Diabetes (Type 1)": row.get('DIABTYP1', '0'),
        "Diabetes (Type 2)": row.get('DIABTYP2', '0'),
        "Diabetes (Unspecified)": row.get('DIABTYP0', '0'),
        "End-stage renal disease": row.get('ESRD', '0'),
        "History of PE/DVT": row.get('HPE', '0'),
        "HIV/AIDS": row.get('EDHIV', '0'),
        "Hyperlipidemia": row.get('HYPLIPID', '0'),
        "Hypertension": row.get('HTN', '0'),
        "Obesity": row.get('OBESITY', '0'),
        "Obstructive sleep apnea": row.get('OSA', '0'),
        "Osteoporosis": row.get('OSTPRSIS', '0'),
        "Substance abuse": row.get('SUBSTAB', '0'),
        "Alcohol abuse": row.get('ETOHAB', '0')
    }


    #collect the names of all conditions that are '1'
    positive_conditions = [name for name, val in chronic_map.items() if val == 'Yes']
    if positive_conditions:
        conditions_str = ", ".join(positive_conditions)
    else:
        conditions_str = "none"

    #Causes
    cause1 = clean_text(row.get('CAUSE1', ''))
    cause2 = clean_text(row.get('CAUSE2', ''))
    cause3 = clean_text(row.get('CAUSE3', ''))
    causes = [str(c) for c in [cause1, cause2, cause3] if c]
    causes_str = ", ".join(causes) if causes else "no specific causes reported"


    # Triage level
    triage_level = row.get('IMMEDR', 'unknown triage level')

    # Construct Vigneete output
    output_str = (
        f"A {age_val}-year-old {sex_str} {arrival_mode_str} at the ED with an "
        f"{injury_str} visit. The patient reported the following primary complaint(s): "
        f"{reasons_str}. Recorded vital signs include temperature {temp_val}, pulse {pulse_val}, "
        f"blood pressure {bpsys_val}/{bpdiast_val}, respiratory rate {resp_val}, and O2 saturation "
        f"{o2sat_val}%. Pain scale was noted as {pain_scale}. The patient has a total of "
        f"{total_chronic} chronic condition(s), including: {conditions_str}. Possible cause(s) "
        f"related to this visit: {causes_str}. | "
        f"Triage_level: {triage_level}."
    )

    return output_str

# Create 'input_text' column by applying create_input_text function row-wise
df['input_text'] = df.apply(create_input_text, axis=1)
# Create 'target_text' column by applying create_output_text function row-wise
df['target_text'] = df.apply(create_output_text, axis=1)

# Split the data into training and testing sets.
train_df, test_df = train_test_split(df, test_size=0.01, random_state=42)

# Convert the training and testing dataframes to Hugging Face Datasets.
# Only the 'input_text' and 'target_text' columns are included in the datasets.
train_dataset = Dataset.from_pandas(train_df[['input_text','target_text']])
test_dataset  = Dataset.from_pandas(test_df[['input_text','target_text']])

# Set the maximum length for source and target sequences
max_source_length = 512  # Maximum length of the input text sequence
max_target_length = 512  # Maximum length of the target text sequence

def preprocess_function(examples):
    """
    Preprocesses the input and target text examples for the model.

    Args:
        examples (dict): A dictionary containing the 'input_text' and 'target_text' fields.

    Returns:
        dict: A dictionary containing the tokenized input IDs and labels.
    """
    inputs = examples['input_text']  # Extract input text from examples
    targets = examples['target_text'] # Extract target text from examples

    # Tokenize the input text
    model_inputs = tokenizer(inputs, max_length=max_source_length, truncation=True)

    # Tokenize the target text using the tokenizer as a target tokenizer
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=True)

    # Add the tokenized labels to the model inputs
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

# Apply the preprocessing function to the training and testing datasets
train_tokenized = train_dataset.map(preprocess_function, batched=True)
test_tokenized  = test_dataset.map(preprocess_function, batched=True)

# Define data collator for sequence-to-sequence tasks
data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)

# Training arguments configuration
training_args = TrainingArguments(
    output_dir="/content/clinical_t5_finetuned-v2", # Output directory for the model checkpoints
    evaluation_strategy="epoch", # Evaluate the model at the end of each epoch
    save_strategy="epoch", # Save the model checkpoints at the end of each epoch
    per_device_train_batch_size=2, # Batch size per device during training
    per_device_eval_batch_size=1, # Batch size per device during evaluation
    num_train_epochs=2, # Number of training epochs
    logging_steps=50, # Log training progress every 50 steps
    load_best_model_at_end=True, # Load the best model at the end of training
    logging_dir="/content/logs", # Directory for storing logs
)

# Create a Trainer instance
trainer = Trainer(
    model=model, # The pre-trained model to fine-tune
    args=training_args, # Training arguments
    train_dataset=train_tokenized, # Training dataset
    eval_dataset=test_tokenized, # Evaluation dataset
    data_collator=data_collator # Data collator for preparing batches
)

"""52fd3b982b7a332431e30316eb603a7ed20e3a90"""

#Run the training loop
trainer.train()

#Get model predictions
predictions = trainer.predict(test_tokenized)
predicted_ids = predictions.predictions
decoded_preds = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)

#Retrieve references from `test_df`
decoded_refs = test_df["target_text"].tolist()

# valuate BERTScore
bertscore_metric = evaluate.load("bertscore")
bertscore_results = bertscore_metric.compute(
    predictions=decoded_preds,
    references=decoded_refs,
    model_type="distilbert-base-uncased"
)

print("BERTScore Precision:", sum(bertscore_results["precision"]) / len(bertscore_results["precision"]))
print("BERTScore Recall:", sum(bertscore_results["recall"]) / len(bertscore_results["recall"]))
print("BERTScore F1:", sum(bertscore_results["f1"]) / len(bertscore_results["f1"]))

# Calculate ROUGE:
rouge = evaluate.load("rouge")
rouge_results = rouge.compute(predictions=decoded_preds, references=decoded_refs)
print("ROUGE Results:", rouge_results)

# Inference on a new row
input_str = df['input_text'].iloc[2] # Get the input text from the third row (index 2) of the dataframe.
input_ids = tokenizer(input_str, return_tensors="pt").input_ids # Tokenize the input string.

input_ids = input_ids.to(model.device) # Move the input IDs to the device the model is on.

output_ids = model.generate( # Generate text based on input IDs.
    input_ids, max_length=256, num_beams=4, early_stopping=True
)
generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True) # Decode the generated token IDs into text.

print("INPUT:", input_str) # Print the input text.
print("GENERATED TEXT:", generated_text) # Print the generated text.

model_generated_texts = []
for i, row in test_df.iterrows():
    # Flatten input and target text from the dataframe row.
    input_str = row["input_text"]
    target_str = row["target_text"]
    # Tokenize the input string using the pre-trained tokenizer.
    input_ids = tokenizer(input_str, return_tensors="pt").input_ids.to(model.device)
    # Generate text using the fine-tuned model.
    output_ids = model.generate(input_ids, max_length=512, num_beams=4)
    # Decode the generated token IDs back into text.
    gen_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    print(f"Ground Truth: {target_str}")
    print(f"GENERATED TEXT: {gen_text}")
    # Append the generated text to the list.
    model_generated_texts.append(gen_text)
# Add a new column to the test dataframe containing the generated text.
test_df["model_generated_text"] = model_generated_texts